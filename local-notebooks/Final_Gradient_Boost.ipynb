{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_df = pd.read_csv('/Users/alitahseen/Desktop/FYP-2024/Machine_learning/Datafiles/Final_Train.csv')\n",
    "test_df = pd.read_csv('/Users/alitahseen/Desktop/FYP-2024/Machine_learning/Datafiles/Final_test.csv')\n",
    "validation_df = pd.read_csv('/Users/alitahseen/Desktop/FYP-2024/Machine_learning/Datafiles/Final_Validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for preprocessing the datasets\n",
    "def preprocess_data(df):\n",
    "    df['local_time'] = pd.to_datetime(df['local_time'])\n",
    "    for time_unit in ['Year', 'Month', 'Day', 'Hour']:\n",
    "        df[time_unit] = getattr(df['local_time'].dt, time_unit.lower())\n",
    "    return df.drop('local_time', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing all the datasets\n",
    "train_df = preprocess_data(train_df)\n",
    "test_df = preprocess_data(test_df)\n",
    "validation_df = preprocess_data(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the feature sets and target variables\n",
    "def get_features_targets(df):\n",
    "    X = df[['Year', 'Month', 'Day', 'Hour', 'Average_Temp']]\n",
    "    y = df['MW']\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = get_features_targets(train_df)\n",
    "X_validation, y_validation = get_features_targets(validation_df)\n",
    "X_test, y_test = get_features_targets(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Function\n",
    "\n",
    "def calculate_metrics(actual, predicted, lower_bound=0, upper_bound=100, iqr_multiplier=1.5):\n",
    "    # Excluding negative actual values if considered invalid\n",
    "    valid_indices = actual > lower_bound\n",
    "    actual = actual[valid_indices]\n",
    "    predicted = predicted[valid_indices]\n",
    "\n",
    "    # MAE and RMSE calculations\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "    # Thresholding for outlier exclusion based on IQR\n",
    "    q1, q3 = np.percentile(actual, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    outlier_threshold_upper = q3 + (iqr * iqr_multiplier)\n",
    "    outlier_threshold_lower = q1 - (iqr * iqr_multiplier)\n",
    "\n",
    "    valid_indices_for_mape = (actual >= outlier_threshold_lower) & (actual <= outlier_threshold_upper)\n",
    "    filtered_actual = actual[valid_indices_for_mape]\n",
    "    filtered_predicted = predicted[valid_indices_for_mape]\n",
    "\n",
    "    # MAPE will be capped at 100 if it goes above 100%\n",
    "    if len(filtered_actual) > 0:\n",
    "        percentage_errors = np.abs((filtered_predicted - filtered_actual) / filtered_actual) * 100\n",
    "        percentage_errors = np.clip(percentage_errors, None, upper_bound)  # Cap percentage errors at upper_bound (100%)\n",
    "        mape = np.mean(percentage_errors)\n",
    "    else:\n",
    "        mape = np.nan\n",
    "\n",
    "    # sMAPE calculation\n",
    "    smape = 100/len(actual) * np.sum(2 * np.abs(predicted - actual) / (np.abs(actual) + np.abs(predicted)))\n",
    "\n",
    "    return mae, mape, smape, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/alitahseen/Desktop/FYP-2024/Machine_learning/notebooks/Trained_Models/best_Gradient_Boost_model.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump\n",
    "\n",
    "\n",
    "# Pipeline for preprocessing and modeling\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', GradientBoostingRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Grid of parameters to search\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200, 300],\n",
    "    'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'model__max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_absolute_error', verbose=1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model retrival\n",
    "best_model_gradient = grid_search.best_estimator_\n",
    "\n",
    "# Save the model to a file\n",
    "model_filename = '/Users/alitahseen/Desktop/FYP-2024/Machine_learning/notebooks/Trained_Models/best_Gradient_Boost_model.joblib'\n",
    "dump(best_model_gradient, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "model_filename = '/Users/alitahseen/Desktop/FYP-2024/Machine_learning/notebooks/Trained_Models/best_Gradient_Boost_model.joblib'\n",
    "\n",
    "loaded_best_model_gradient = load(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics after tuning (MAE, MAPE, sMAPE,RMSE): (49.95926375923622, 60.54155952311222, 61.72224857736984, 76.97656701281181)\n"
     ]
    }
   ],
   "source": [
    "# Predicting and evaluating on the validation set\n",
    "predictions_validation = loaded_best_model_gradient.predict(X_validation)\n",
    "metrics_validation = calculate_metrics(y_validation, predictions_validation)\n",
    "print(\"Validation Metrics after tuning (MAE, MAPE, sMAPE,RMSE):\", metrics_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics with Gradient Boosting (MAE, MAPE, sMAPE, RMSE): (22.417985977090343, 26.61286998284016, 33.21977198571935, 41.16166733794306)\n"
     ]
    }
   ],
   "source": [
    "# Predicting and evaluating on the test set\n",
    "predictions_test = loaded_best_model_gradient.predict(X_test)\n",
    "metrics_test = calculate_metrics(y_test, predictions_test)\n",
    "print(\"Test Metrics with Gradient Boosting (MAE, MAPE, sMAPE, RMSE):\", metrics_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
